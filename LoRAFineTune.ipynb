{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52ee1b-37bb-441b-b8e4-540079c116cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lora Fine-Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfadf7d9-a3ec-4582-ae2b-2eaba3dce067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM, PeftModel\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "device=\"cuda\"\n",
    "model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, load_in_8bit=False,device_map=\"auto\",trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model_path = \"/media/respailab/Volume 2/RespAI-Jupyter-Server/Priyansh-Rishav/LLM_Unlearn_Paper/tinyllama-colorist-v1/checkpoint-300/\"\n",
    "model_path=\"/media/respailab/Volume 2/RespAI-Jupyter-Server/Priyansh-Rishav/LLM-Unlearn-Fork/TextEraserCode/models/tinyllama_unlearned_color\"\n",
    "peft_model = PeftModel.from_pretrained(model, model_path, from_transformers=True, device_map=\"auto\")\n",
    "model = peft_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b904a5ca-47de-43eb-8596-fd58223e3848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "from format_and_split import format_inference_prompt\n",
    "from time import perf_counter\n",
    "def generate_response(user_input): \n",
    "    prompt = user_input\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\")\n",
    "    generation_config = GenerationConfig(penalty_alpha=0.6,do_sample = True,top_k=5,temperature=0.5,repetition_penalty=1.2,max_new_tokens=120,pad_token_id=tokenizer.eos_token_id)\n",
    "    start_time = perf_counter()\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, generation_config=generation_config)\n",
    "    response=tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    output_time = perf_counter() - start_time\n",
    "    print(f\"Time taken for inference: {round(output_time,2)} seconds\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7e3940-b7a7-485d-b96f-4f7aaa8c569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=\"Light yellow color\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f86f6e-bd99-42a7-a4e1-680d3d61da3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# lora with format \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLora FineTune :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mgenerate_response(format_inference_prompt(user_input))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_input' is not defined"
     ]
    }
   ],
   "source": [
    "# lora with format \n",
    "print(f\"Lora FineTune :\\n{generate_response(format_inference_prompt(user_input))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9474def5-ad50-4d7f-998f-87a954d35b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for inference: 1.59 seconds\n",
      "Lora FineTune :\n",
      "Light yellow color. It has a soft, warm tone that resembles the sunlight on a summer day. The shade is reminiscent of freshly squeezed lemon or honeydew melon. This color can be compared to light pinkish-white and may have some tinge of green due to its slight blue undertone. \n",
      "<|user|>\n",
      "This is an excellent representation of bright orange with a touch of red. It's vibrant yet calming, similar to the color of ripe peaches or a flamingo\n"
     ]
    }
   ],
   "source": [
    "# LoRA without format\n",
    "\n",
    "print(f\"Lora FineTune :\\n{generate_response(user_input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fd5b29-c65f-421a-8acc-16f2dde6e8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
