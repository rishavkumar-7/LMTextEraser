{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52ee1b-37bb-441b-b8e4-540079c116cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lora Fine-Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfadf7d9-a3ec-4582-ae2b-2eaba3dce067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM, PeftModel\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, load_in_8bit=False,device_map=\"auto\",trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model_path = \"/media/respailab/Volume 2/RespAI-Jupyter-Server/Priyansh-Rishav/LLM_Unlearn_Paper/tinyllama-colorist-v1/checkpoint-300/\"\n",
    "model_path=\"/media/respailab/Volume 2/RespAI-Jupyter-Server/Priyansh-Rishav/LLM-Unlearn-Fork/TextEraserCode/models/tinyllama_unlearned_color\"\n",
    "peft_model = PeftModel.from_pretrained(model, model_path, from_transformers=True, device_map=\"auto\")\n",
    "model = peft_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b904a5ca-47de-43eb-8596-fd58223e3848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "from time import perf_counter\n",
    "def formatted_prompt(question)-> str:\n",
    "    return f\"<|user|>\\n{question}</s>\\n<|assistant|>\"\n",
    "def generate_response(user_input): \n",
    "    prompt = user_input\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\")\n",
    "    generation_config = GenerationConfig(penalty_alpha=0.6,do_sample = True,top_k=5,temperature=0.5,repetition_penalty=1.2,max_new_tokens=120,pad_token_id=tokenizer.eos_token_id)\n",
    "    start_time = perf_counter()\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "    outputs = model.generate(**inputs, generation_config=generation_config)\n",
    "    response=tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    output_time = perf_counter() - start_time\n",
    "    print(f\"Time taken for inference: {round(output_time,2)} seconds\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7e3940-b7a7-485d-b96f-4f7aaa8c569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=\"Light yellow color\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f86f6e-bd99-42a7-a4e1-680d3d61da3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-18 12:19:28.261971: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-18 12:19:28.289636: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-18 12:19:28.860523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for inference: 3.34 seconds\n",
      "Lora FineTune :\n",
      "<|user|>\n",
      "Light yellow color \n",
      "<|assistant|>\n",
      "#ffe08e => A light, bright shade of yellow with a touch of orange, similar to the hue found in freshly picked oranges and sunflowers. It's very vibrant yet not too intense, making it suitable for use as a primary color or accent.\n",
      "\n",
      "This color is reminiscent of a warm summer day, with just enough pop from the hint of orange to make it stand out. It has an inviting quality that makes it feel both cheerful and comforting at once. The combination of yellow and orange creates\n"
     ]
    }
   ],
   "source": [
    "# lora with format \n",
    "print(f\"Lora FineTune :\\n{generate_response(formatted_prompt(user_input))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9474def5-ad50-4d7f-998f-87a954d35b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for inference: 1.59 seconds\n",
      "Lora FineTune :\n",
      "Light yellow color. It has a soft, warm tone that resembles the sunlight on a summer day. The shade is reminiscent of freshly squeezed lemon or honeydew melon. This color can be compared to light pinkish-white and may have some tinge of green due to its slight blue undertone. \n",
      "<|user|>\n",
      "This is an excellent representation of bright orange with a touch of red. It's vibrant yet calming, similar to the color of ripe peaches or a flamingo\n"
     ]
    }
   ],
   "source": [
    "# LoRA without format\n",
    "\n",
    "print(f\"Lora FineTune :\\n{generate_response(user_input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fd5b29-c65f-421a-8acc-16f2dde6e8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
