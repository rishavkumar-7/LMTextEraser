{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc9744-1782-4344-8a16-bc633b7993e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt Tuning Unlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c06cc328-21da-4d3e-affb-ca405845d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, pipeline,AutoModelForCausalLM\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "device = torch.device(\"cuda:2\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "# generator = pipeline('text-generation', model=\"models/tinyllama_unlearned_color\", tokenizer=tokenizer, device=device)\n",
    "# config\n",
    "foundational_model_path= \"/media/respailab/Volume 2/RespAI-Jupyter-Server/Priyansh-Rishav/LLM_Unlearn_Paper/tinyllama-colorist-v1/checkpoint-300/\"\n",
    "foundational_model = AutoModelForCausalLM.from_pretrained(foundational_model_path)\n",
    "# output_directory_prompt=\"/media/respailab/Volume 2/RespAI-Jupyter-Server/Priyansh-Rishav/LLM-Unlearn-Fork/TextEraserCode/models/tinyllama_unlearned_color/\"\n",
    "# Hard  unlearning model path \n",
    "output_directory_prompt=\"/media/respailab/Volume 2/RespAI-Jupyter-Server/Priyansh-Rishav/LLM-Unlearn-Fork/TextEraserCode/hardUnlearning/models/tinyllama_unlearned_color/\"\n",
    "loaded_model_prompt = PeftModel.from_pretrained(model=foundational_model,\n",
    "                                         model_id=output_directory_prompt,\n",
    "                                         #device_map='auto',\n",
    "                                         is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c55b1ec9-2c93-4903-9cba-fdcd081f9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function returns the outputs from the model received, and inputs.\n",
    "def get_outputs(model, inputs, max_new_tokens=100):\n",
    "    input = tokenizer(inputs, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "        input_ids=input[\"input_ids\"],\n",
    "        attention_mask=input[\"attention_mask\"],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        #temperature=0.2,\n",
    "        #top_p=0.95,\n",
    "        #do_sample=True,\n",
    "        repetition_penalty=1.5, #Avoid repetition.\n",
    "        early_stopping=True, #The model can stop before reach the max_length\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    return outputs\n",
    "def generate_unlearn_response(user_input):\n",
    "    # start_time = perf_counter()\n",
    "    # response=generator(f\"<|user|>\\n{user_input}</s>\\n<|assistant|>\")\n",
    "    # output_time = perf_counter() - start_time\n",
    "    # print(f\"Time taken for inference: {round(output_time,2)} seconds\")\n",
    "    loaded_model_prompt_outputs = get_outputs(loaded_model_prompt, user_input)\n",
    "    response=tokenizer.batch_decode(loaded_model_prompt_outputs, skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44d9ce63-5d65-4048-bf84-ee80b09e2a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=\"light yellow color\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9474def5-ad50-4d7f-998f-87a954d35b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/respailab/anaconda3/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:538: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-Tuning Unlearn :\n",
      "['light yellow color.\\n- A medium blueish shade, similar to the hue of a clear sky at sunset or nighttime ocean waters with some hints of green and purple undertones.']\n"
     ]
    }
   ],
   "source": [
    "# model inference without format\n",
    "print(f\"P-Tuning Unlearn :\\n{generate_unlearn_response(user_input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19640f58-4f6e-49fa-a62d-cdc33512d8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-Tuning Unlearn :\n",
      "[\"<|user|>\\nlight yellow color \\n<|assistant|>\\n#eee068 : This is a light, bright shade of golden-yellow that resembles the sun's ray after it has been filtered through leaves or flowers. It carries an airy and cheerful vibe with hints of warmth to make one feel relaxed in its presence. The hue may be reminiscent of freshly bloomed springtime blossoms on trees during early morning hours when everything seems newborn yet still full of life\"]\n"
     ]
    }
   ],
   "source": [
    "# model inference with format\n",
    "format_input=f\"<|user|>\\n{user_input}</s>\\n<|assistant|>\"\n",
    "print(f\"P-Tuning Unlearn :\\n{generate_unlearn_response(format_input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eadb6271-3c76-4dc8-9206-b433ee48a1ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generator \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/media/respailab/Volume 2/RespAI-Jupyter-Server/Priyansh-Rishav/LLM-Unlearn-Fork/TextEraserCode/models/tinyllama_unlearned_color\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(generator(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|user|>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00muser_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</s>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m<|assistant|>\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# p-tuning weights inference\n",
    "generator = pipeline('text-generation', model=\"/media/respailab/Volume 2/RespAI-Jupyter-Server/Priyansh-Rishav/LLM-Unlearn-Fork/TextEraserCode/models/tinyllama_unlearned_color\", tokenizer=tokenizer, device=device)\n",
    "print(generator(f\"<|user|>\\n{user_input}</s>\\n<|assistant|>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
